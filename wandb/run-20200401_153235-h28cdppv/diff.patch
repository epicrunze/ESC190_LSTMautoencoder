diff --git a/bin, but it's python/__pycache__/structs.cpython-37.pyc b/bin, but it's python/__pycache__/structs.cpython-37.pyc
index 852d7fe..12d1a5d 100644
Binary files a/bin, but it's python/__pycache__/structs.cpython-37.pyc and b/bin, but it's python/__pycache__/structs.cpython-37.pyc differ
diff --git a/bin, but it's python/__pycache__/utils.cpython-37.pyc b/bin, but it's python/__pycache__/utils.cpython-37.pyc
index 1d7180a..c4d5daf 100644
Binary files a/bin, but it's python/__pycache__/utils.cpython-37.pyc and b/bin, but it's python/__pycache__/utils.cpython-37.pyc differ
diff --git a/bin, but it's python/main.ipynb b/bin, but it's python/main.ipynb
index 2720081..756d316 100644
--- a/bin, but it's python/main.ipynb	
+++ b/bin, but it's python/main.ipynb	
@@ -8,7 +8,7 @@
     "name": "ipython",
     "version": 3
    },
-   "version": "3.7.5-final"
+   "version": "3.7.4-final"
   },
   "orig_nbformat": 2,
   "file_extension": ".py",
@@ -18,8 +18,8 @@
   "pygments_lexer": "ipython3",
   "version": 3,
   "kernelspec": {
-   "name": "python37564bitprojenvvenv64a22ff99f0e49308299b7eb2e75ef79",
-   "display_name": "Python 3.7.5 64-bit ('projenv': venv)"
+   "name": "python37464bitprojenvvenv5183e90ff64f49ee83b8a29c549cc789",
+   "display_name": "Python 3.7.4 64-bit ('projenv': venv)"
   }
  },
  "cells": [
@@ -37,47 +37,30 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 11,
    "metadata": {},
    "outputs": [],
-   "source": [
-    "def process_line(string):\n",
-    "    '''takes in a line of the format: <word> <def>; <def>;...\n",
-    "    returns words: str, defs: list\n",
-    "    '''\n",
-    "    defs = []\n",
-    "    splitted = string.split()\n",
-    "    word = splitted.pop(0)\n",
-    "    for each in (\" \".join(splitted)).split(\";\"):\n",
-    "        defs.append(each.strip())\n",
-    "    return word, defs"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": "['half-length', 'wowie', 'half-length', 'wowie', 'half-length', 'wowie']\n"
-    }
-   ],
    "source": [
     "datafile = \"memes.txt\"\n",
-    "dictionary = None\n",
-    "with open(datafile, \"r\") as input_doc:\n",
-    "    for line in input_doc:\n",
-    "        word, defs = process_line(line)\n",
-    "        #process defs\n",
-    "        embeddings = defs\n",
-    "        nodeyboi = structs.Node(word, defs, embeddings)\n",
-    "        if not dictionary:\n",
-    "            dictionary = structs.Dictionary(nodeyboi)\n",
-    "            continue\n",
-    "        dictionary.balanced_insert(nodeyboi)\n",
-    "print(dictionary.return_dict())"
+    "\n",
+    "def data2dict(datafile):\n",
+    "    dictionary = None\n",
+    "    with open(datafile, \"r\") as input_doc:\n",
+    "        for line in input_doc:\n",
+    "            word, defs = utils.process_line(line)\n",
+    "            #process defs\n",
+    "            embeddings = defs\n",
+    "            nodeyboi = structs.Node(word, defs, embeddings)\n",
+    "            if not dictionary:\n",
+    "                dictionary = structs.Dictionary(nodeyboi)\n",
+    "                continue\n",
+    "            dictionary.balanced_insert(nodeyboi)\n",
+    "    return dictionary\n",
+    "\n",
+    "def dict2data(dictionary, writefile):\n",
+    "    \n",
+    "\n",
+    "dictionary = data2dict(datafile)"
    ]
   },
   {
diff --git a/bin, but it's python/structs.py b/bin, but it's python/structs.py
index 64de9ae..258f606 100644
--- a/bin, but it's python/structs.py	
+++ b/bin, but it's python/structs.py	
@@ -1,7 +1,7 @@
 import numpy as np
 
 class Node:
-    def __init__(self, word: str, definition: list, encoded_vec: "list(np.array)", left = None, right= None, parent= None, height: int = 1, bf: int = 0):
+    def __init__(self, word: str, definition: list, encoded_vec, left = None, right= None, parent= None, height: int = 1, bf: int = 0):
         self.word = word
         self.definition = definition
         self.vec = encoded_vec
@@ -142,10 +142,14 @@ class Dictionary:
         else:
             return True
 
-    def return_dict(self, curr="yeet", listy=[]):
+    def return_dict(self, curr="yeet"):
         curr = curr if curr != "yeet" else self.root
+        listy = []
         if curr:
-            listy = self.return_dict(curr.left, listy)
+            listy.extend(self.return_dict(curr.left))
             listy.append(curr.word)
-            listy = self.return_dict(curr.right, listy)
-        return listy
\ No newline at end of file
+            listy.extend(self.return_dict(curr.right))
+        return listy
+
+    def write2file(self, filename):
+        pass
\ No newline at end of file
diff --git a/bin, but it's python/utils.py b/bin, but it's python/utils.py
index e69de29..ce51497 100644
--- a/bin, but it's python/utils.py	
+++ b/bin, but it's python/utils.py	
@@ -0,0 +1,13 @@
+
+
+
+def process_line(string):
+    '''takes in a line of the format: <word> <def>; <def>;...
+    returns words: str, defs: list
+    '''
+    defs = []
+    splitted = string.split()
+    word = splitted.pop(0)
+    for each in (" ".join(splitted)).split(";"):
+        defs.append(each.strip())
+    return word, defs
\ No newline at end of file
diff --git a/dataProcessing.ipynb b/dataProcessing.ipynb
index 6eff425..9fd6964 100644
--- a/dataProcessing.ipynb
+++ b/dataProcessing.ipynb
@@ -169,14 +169,7 @@
    "execution_count": 12,
    "metadata": {},
    "outputs": [],
-   "source": [
-    "def to_one_hot(x):\n",
-    "    vocab_size = 46948 + 1\n",
-    "    #output = tf.zeros((x.shape)+(vocab_size,))\n",
-    "    #mask = np.array(x) > 0\n",
-    "    label = tf.one_hot(x, vocab_size)\n",
-    "    return x, label[:, 1:]"
-   ]
+   "source": []
   },
   {
    "cell_type": "code",
@@ -198,7 +191,7 @@
     "x_train = x_train.astype(\"int32\")\n",
     "np.random.shuffle(x_train)\n",
     "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
-    "dataset = dataset.map(to_one_hot)\n",
+    "dataset = dataset.map(utils.to_one_hot)\n",
     "dataset = dataset.shuffle(1000).batch(config.batch_size)"
    ]
   },
diff --git a/universalSentenceEmbedding.ipynb b/universalSentenceEmbedding.ipynb
index 635e2c4..9c0a4ac 100644
--- a/universalSentenceEmbedding.ipynb
+++ b/universalSentenceEmbedding.ipynb
@@ -37,7 +37,7 @@
      "output_type": "display_data",
      "data": {
       "text/plain": "<IPython.core.display.HTML object>",
-      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/38jpvgr8\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/38jpvgr8</a><br/>\n            "
+      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/h99at90o\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/h99at90o</a><br/>\n            "
      },
      "metadata": {}
     }
@@ -61,7 +61,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
@@ -82,7 +82,6 @@
     "word2num, num2word = utils.get_word_dicts(definitions)\n",
     "\n",
     "num2word[0] = \"\"\n",
-    "\n",
     "vocab_size = len(list(word2num.keys()))\n",
     "\n",
     "print(\"Size of definition vocabulary: {}\".format(vocab_size))\n",
@@ -91,7 +90,51 @@
     "\n",
     "x_train = utils.defs_to_np(def_vectors, max_length)\n",
     "\n",
-    "print(x_train.shape)"
+    "print(x_train.shape)\n",
+    "vocab_size += 1"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "metadata": {},
+   "outputs": [
+    {
+     "output_type": "error",
+     "ename": "ValueError",
+     "evalue": "Input 0 of layer repeat_vector_1 is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: [None, 1, 512]",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
+      "\u001b[1;32m<ipython-input-11-6572905954ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0minputlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrepeatlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdecodingLSTM1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeatlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdecodingLSTM2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecodingLSTM1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[1;32m--> 737\u001b[1;33m                                               self.name)\n\u001b[0m\u001b[0;32m    738\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[0;32m    739\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    175\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                          str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer repeat_vector_1 is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: [None, 1, 512]"
+     ]
+    }
+   ],
+   "source": [
+    "#creating decoder model, taking in embedded strings, and calculating a resultant from them\n",
+    "\n",
+    "from tensorflow.keras.models import Model, Sequential\n",
+    "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM, RepeatVector, TimeDistributed, Lambda\n",
+    "from tensorflow.keras.optimizers import Adam\n",
+    "from tensorflow.keras.losses import categorical_crossentropy\n",
+    "\n",
+    "\n",
+    "inputlayer = Input(shape=(512,))\n",
+    "repeatlayer = RepeatVector(max_length)(inputlayer)\n",
+    "decodingLSTM1 = LSTM(32, return_sequences=True)(repeatlayer)\n",
+    "decodingLSTM2 = LSTM(64, return_sequences=True)(decodingLSTM1)\n",
+    "denseboi = TimeDistributed(Dense(100, activation=\"relu\"))(decodingLSTM2)\n",
+    "finalDense = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(denseboi)\n",
+    "output = finalDense\n",
+    "\n",
+    "model = Model(inputs=inputlayer, outputs=output)\n",
+    "optimizer = Adam(learning_rate = 0.0003)\n",
+    "model.compile(loss = categorical_crossentropy, optimizer = optimizer, metrics = [\"accuracy\"])\n",
+    "\n",
+    "model.summary()"
    ]
   },
   {
@@ -107,7 +150,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 22,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -115,65 +158,107 @@
     "from functools import partial\n",
     "\n",
     "def parse_defs(definition_vec, model, num2word, vocab_size):\n",
-    "    vocab_size = vocab_size + 1\n",
-    "    definition_string = tf.strings.join(tf.map_fn(lambda x: num2word[x], definition_vec))\n",
-    "    embedded_tens = model([definition_string])\n",
+    "    converted_tens = num2word.lookup(definition_vec)\n",
+    "    definition_string = tf.strings.join(tf.split(converted_tens, num_or_size_splits=converted_tens.shape[0], axis = 0))\n",
+    "    embedded_tens = model(definition_string)\n",
+    "    tf.print(embedded_tens.shape)\n",
     "    label = tf.one_hot(definition_vec, vocab_size)\n",
-    "    return embedded_tens, label[:, 1:]\n",
+    "    return embedded_tens, label\n",
+    "\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# creating lookup dictionary\n",
     "\n",
-    ""
+    "keys = list(num2word.keys())\n",
+    "values = [num2word[each] for each in keys]\n",
+    "\n",
+    "tf_num2word = tf.lookup.StaticHashTable(\n",
+    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
+    "        keys=tf.constant(keys),\n",
+    "        values=tf.constant(values, dtype=tf.string),\n",
+    "    ),\n",
+    "    default_value=tf.constant(\"\"),\n",
+    "    name=\"num2wordlookup\"\n",
+    ")"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 7,
    "metadata": {},
+   "outputs": [],
+   "source": [
+    "config.batch_size = 16\n",
+    "#config.steps_per_epoch = 100\n",
+    "config.epochs = 1"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
+   "metadata": {},
    "outputs": [
     {
      "output_type": "stream",
      "name": "stdout",
-     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 512)]             0         \n_________________________________________________________________\nrepeat_vector (RepeatVector) (None, 54, 512)           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 54, 32)            69760     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 54, 64)            24832     \n_________________________________________________________________\ntime_distributed (TimeDistri (None, 54, 100)           6500      \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, 54, 46948)         4741748   \n=================================================================\nTotal params: 4,842,840\nTrainable params: 4,842,840\nNon-trainable params: 0\n_________________________________________________________________\n"
+     "text": "46949\n"
     }
    ],
    "source": [
-    "#creating decoder model, taking in embedded strings, and calculating a resultant from them\n",
-    "\n",
-    "from tensorflow.keras.models import Model, Sequential\n",
-    "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM, RepeatVector, TimeDistributed, Lambda\n",
-    "from tensorflow.keras.optimizers import Adam\n",
-    "from tensorflow.keras.losses import categorical_crossentropy\n",
-    "\n",
-    "\n",
-    "inputlayer = Input(shape=(512,))\n",
-    "repeatlayer = RepeatVector(max_length)(inputlayer)\n",
-    "decodingLSTM1 = LSTM(32, return_sequences=True)(repeatlayer)\n",
-    "decodingLSTM2 = LSTM(64, return_sequences=True)(decodingLSTM1)\n",
-    "denseboi = TimeDistributed(Dense(100, activation=\"relu\"))(decodingLSTM2)\n",
-    "finalDense = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(denseboi)\n",
-    "output = finalDense\n",
-    "\n",
-    "model = Model(inputs=inputlayer, outputs=output)\n",
-    "optimizer = Adam(learning_rate = 0.0003)\n",
-    "model.compile(loss = categorical_crossentropy, optimizer = optimizer, metrics = [\"accuracy\"])\n",
-    "\n",
-    "model.summary()"
+    "#creating dataset\n",
+    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
+    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
+    "print(vocab_size)\n",
+    "dataset = dataset.map(partial(parse_defs, model=embed, num2word=tf_num2word, vocab_size=vocab_size))\n",
+    "dataset = dataset.shuffle(1000).batch(config.batch_size)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 9,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
+    "save_model = ModelCheckpoint(filepath=\"USED.1.weights.{epoch:02d}.h5\", monitor='accuracy', save_weights_only=True, mode='auto', verbose=1)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 23,
+   "execution_count": 10,
    "metadata": {},
    "outputs": [
+    {
+     "output_type": "display_data",
+     "data": {
+      "text/plain": "<IPython.core.display.HTML object>",
+      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/q8nmzm30\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/q8nmzm30</a><br/>\n            "
+     },
+     "metadata": {}
+    },
     {
      "output_type": "error",
-     "ename": "TypeError",
-     "evalue": "in converted code:\n\n    <ipython-input-22-066751b03f5f>:6 parse_defs  *\n        definition_string = tf.strings.join(tf.map_fn(lambda x: num2word[x], definition_vec))\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:268 map_fn\n        maximum_iterations=n)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py:2675 while_loop\n        back_prop=back_prop)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:194 while_loop\n        add_control_dependencies=add_control_dependencies)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:978 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:172 wrapped_body\n        outputs = body(*_pack_sequence_as(orig_loop_vars, args))\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:257 compute\n        packed_fn_values = fn(packed_values)\n    C:\\Users\\DS\\AppData\\Local\\Temp\\tmp3nk2ssnl.py:11 <lambda>\n        definition_string = ag__.converted_call(tf.strings.join, (ag__.converted_call(tf.map_fn, (lambda x: num2word[x], definition_vec), None, fscope),), None, fscope)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:705 __hash__\n        raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\n\n    TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\n",
+     "ename": "ValueError",
+     "evalue": "in converted code:\n\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected input_1 to have 2 dimensions, but got array with shape (None, None, 512)\n",
      "traceback": [
       "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[1;32m<ipython-input-23-cbaf6daccc2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://tfhub.dev/google/universal-sentence-encoder/4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_defs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#dataset = dataset.shuffle(1000).batch(config.batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1586\u001b[0m     \"\"\"\n\u001b[0;32m   1587\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1588\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m       return ParallelMapDataset(\n",
-      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3886\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3887\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3888\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3889\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[0;32m   3890\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
+      "\u001b[1;32m<ipython-input-10-26e685e66b76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\wandb\\keras\\__init__.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    682\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[1;32m-> 1591\u001b[1;33m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3926\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
       "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3147\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 2395\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2396\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
@@ -183,16 +268,807 @@
       "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3139\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3140\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-22-066751b03f5f>:6 parse_defs  *\n        definition_string = tf.strings.join(tf.map_fn(lambda x: num2word[x], definition_vec))\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:268 map_fn\n        maximum_iterations=n)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py:2675 while_loop\n        back_prop=back_prop)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:194 while_loop\n        add_control_dependencies=add_control_dependencies)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:978 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:172 wrapped_body\n        outputs = body(*_pack_sequence_as(orig_loop_vars, args))\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:257 compute\n        packed_fn_values = fn(packed_values)\n    C:\\Users\\DS\\AppData\\Local\\Temp\\tmp3nk2ssnl.py:11 <lambda>\n        definition_string = ag__.converted_call(tf.strings.join, (ag__.converted_call(tf.map_fn, (lambda x: num2word[x], definition_vec), None, fscope),), None, fscope)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:705 __hash__\n        raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\n\n    TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\n"
+      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    c:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected input_1 to have 2 dimensions, but got array with shape (None, None, 512)\n"
      ]
     }
    ],
    "source": [
-    "#creating dataset\n",
-    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
-    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
-    "dataset = dataset.map(partial(parse_defs, model=embed, num2word=num2word, vocab_size=vocab_size))\n",
-    "#dataset = dataset.shuffle(1000).batch(config.batch_size)"
+    "wandb.init()\n",
+    "model.fit(dataset, epochs=config.epochs, callbacks=[WandbCallback(), save_model])"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 12,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "def output2string(words, num2word):\n",
+    "    stringboi = \"\"\n",
+    "    for sentence in words:\n",
+    "        for word in sentence:\n",
+    "            stringboi += num2word[word]\n",
+    "            stringboi += \" \"\n",
+    "        stringboi += \"\\n\"\n",
+    "    return stringboi"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 13,
+   "metadata": {
+    "tags": [
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend",
+     "outputPrepend"
+    ]
+   },
+   "outputs": [
+    {
+     "output_type": "stream",
+     "name": "stdout",
+     "text": "\"\"]\n[51 18 855 ... 0 0 0]\n[\"promoting\" \"or\" \"enhancing\" ... \"\" \"\" \"\"]\n[107 5 856 ... 0 0 0]\n[\"involving\" \"advantage\" \"or\" ... \"\" \"\" \"\"]\n[527 855 5 ... 0 0 0]\n[\"manifesting\" \"partiality\" \"\" ... \"\" \"\" \"\"]\n[859 860 0 ... 0 0 0]\n[\"constituting\" \"a\" \"disadvantage\" ... \"\" \"\" \"\"]\n[194 97 861 ... 0 0 0]\n[\"involving\" \"disadvantage\" \"or\" ... \"\" \"\" \"\"]\n[527 861 5 ... 0 0 0]\n[\"willing\" \"to\" \"undertake\" ... \"\" \"\" \"\"]\n[863 9 864 ... 0 0 0]\n[\"disposed\" \"to\" \"venture\" ... \"\" \"\" \"\"]\n[521 9 869 ... 0 0 0]\n[\"involving\" \"risk\" \"or\" ... \"\" \"\" \"\"]\n[527 871 5 ... 0 0 0]\n[\"flamboyantly\" \"adventurous\" \"\" ... \"\" \"\" \"\"]\n[872 873 0 ... 0 0 0]\n[\"lacking\" \"in\" \"boldness\" ... \"\" \"\" \"\"]\n[83 53 874 ... 0 0 0]\n[\"secure\" \"from\" \"risk\" ... \"\" \"\" \"\"]\n[875 15 871 ... 0 0 0]\n[\"worthy\" \"of\" \"being\" ... \"\" \"\" \"\"]\n[267 17 36 ... 0 0 0]\n[\"prudent\" \"or\" \"wise\" ... \"\" \"\" \"\"]\n[878 5 879 ... 0 0 0]\n[\"wiser\" \"or\" \"more\" ... \"\" \"\" \"\"]\n[880 5 170 ... 0 0 0]\n[\"wise\" \"or\" \"advantageous\" ... \"\" \"\" \"\"]\n[879 5 881 ... 0 0 0]\n[\"not\" \"prudent\" \"or\" ... \"\" \"\" \"\"]\n[12 878 5 ... 0 0 0]\n[\"not\" \"recommended\" \"\" ... \"\" \"\" \"\"]\n[12 876 0 ... 0 0 0]\n[\"having\" \"the\" \"benefit\" ... \"\" \"\" \"\"]\n[1 2 884 ... 0 0 0]\n[\"carefully\" \"weighed\" \"\" ... \"\" \"\" \"\"]\n[889 890 0 ... 0 0 0]\n[\"without\" \"careful\" \"prior\" ... \"\" \"\" \"\"]\n[88 885 886 ... 0 0 0]\n[\"depending\" \"on\" \"free\" ... \"\" \"\" \"\"]\n[892 23 645 ... 0 0 0]\n[\"living\" \"or\" \"active\" ... \"\" \"\" \"\"]\n[243 5 446 ... 0 0 0]\n[\"taking\" \"place\" \"in\" ... \"\" \"\" \"\"]\n[110 733 53 ... 0 0 0]\n[\"living\" \"or\" \"active\" ... \"\" \"\" \"\"]\n[243 5 446 ... 0 0 0]\n[\"based\" \"on\" \"or\" ... \"\" \"\" \"\"]\n[897 23 5 ... 0 0 0]\n[\"enhancing\" \"respiratory\" \"and\" ... \"\" \"\" \"\"]\n[856 900 92 ... 0 0 0]\n[\"not\" \"aerobic\" \"\" ... \"\" \"\" \"\"]\n[12 903 0 ... 0 0 0]\n[\"concerning\" \"or\" \"characterized\" ... \"\" \"\" \"\"]\n[904 5 190 ... 0 0 0]\n[\"satisfying\" \"aesthetic\" \"standards\" ... \"\" \"\" \"\"]\n[907 908 909 ... 0 0 0]\n[\"serving\" \"an\" \"aesthetic\" ... \"\" \"\" \"\"]\n[911 18 908 ... 0 0 0]\n[\"having\" \"qualities\" \"unique\" ... \"\" \"\" \"\"]\n[1 681 913 ... 0 0 0]\n[\"taking\" \"delight\" \"in\" ... \"\" \"\" \"\"]\n[110 916 53 ... 0 0 0]\n[\"violating\" \"aesthetic\" \"canons\" ... \"\" \"\" \"\"]\n[917 908 918 ... 0 0 0]\n[\"deficient\" \"in\" \"tastefulness\" ... \"\" \"\" \"\"]\n[246 53 919 ... 0 0 0]\n[\"lacking\" \"aesthetic\" \"sensibility\" ... \"\" \"\" \"\"]\n[83 908 920 ... 0 0 0]\n[\"acted\" \"upon\" \"\" ... \"\" \"\" \"\"]\n[921 922 0 ... 0 0 0]\n[\"influenced\" \"\" \"\" ... \"\" \"\" \"\"]\n[923 0 0 ... 0 0 0]\n[\"deeply\" \"or\" \"markedly\" ... \"\" \"\" \"\"]\n[924 5 925 ... 0 0 0]\n[\"affected\" \"by\" \"something\" ... \"\" \"\" \"\"]\n[251 69 11 ... 0 0 0]\n[\"infatuated\" \"with\" \"or\" ... \"\" \"\" \"\"]\n[927 44 5 ... 0 0 0]\n[\"likely\" \"to\" \"be\" ... \"\" \"\" \"\"]\n[932 9 59 ... 0 0 0]\n[\"be\" \"affected\" \"with\" ... \"\" \"\" \"\"]\n[59 251 44 ... 0 0 0]\n[\"affected\" \"by\" \"or\" ... \"\" \"\" \"\"]\n[251 69 5 ... 0 0 0]\n[\"undergoing\" \"no\" \"change\" ... \"\" \"\" \"\"]\n[936 476 524 ... 0 0 0]\n[\"not\" \"affected\" \"by\" ... \"\" \"\" \"\"]\n[12 251 69 ... 0 0 0]\n[\"above\" \"being\" \"affected\" ... \"\" \"\" \"\"]\n[937 36 251 ... 0 0 0]\n[\"not\" \"moved\" \"to\" ... \"\" \"\" \"\"]\n[12 938 9 ... 0 0 0]\n[\"not\" \"influenced\" \"or\" ... \"\" \"\" \"\"]\n[12 923 5 ... 0 0 0]\n[\"speaking\" \"or\" \"behaving\" ... \"\" \"\" \"\"]\n[941 5 942 ... 0 0 0]\n[\"struggling\" \"for\" \"effect\" ... \"\" \"\" \"\"]\n[945 154 569 ... 0 0 0]\n[\"artificially\" \"formal\" \"\" ... \"\" \"\" \"\"]\n[946 947 0 ... 0 0 0]\n[\"lacking\" \"spontaneity\" \"\" ... \"\" \"\" \"\"]\n[83 948 0 ... 0 0 0]\n[\"not\" \"natural\" \"\" ... \"\" \"\" \"\"]\n[12 949 0 ... 0 0 0]\n[\"overly\" \"embellished\" \"\" ... \"\" \"\" \"\"]\n[950 752 0 ... 0 0 0]\n[\"having\" \"unnatural\" \"mannerisms\" ... \"\" \"\" \"\"]\n[1 951 952 ... 0 0 0]\n[\"affectedly\" \"mellow\" \"and\" ... \"\" \"\" \"\"]\n[953 954 92 ... 0 0 0]\n[\"free\" \"of\" \"artificiality\" ... \"\" \"\" \"\"]\n[645 17 956 ... 0 0 0]\n[\"sincere\" \"and\" \"genuine\" ... \"\" \"\" \"\"]\n[957 92 958 ... 0 0 0]\n[\"free\" \"from\" \"artificiality\" ... \"\" \"\" \"\"]\n[645 15 956 ... 0 0 0]\n[\"without\" \"artificiality\" \"\" ... \"\" \"\" \"\"]\n[88 956 0 ... 0 0 0]\n[\"natural\" \"\" \"\" ... \"\" \"\" \"\"]\n[949 0 0 ... 0 0 0]\n[\"not\" \"self-conscious\" \"\" ... \"\" \"\" \"\"]\n[12 959 0 ... 0 0 0]\n[\"flowing\" \"naturally\" \"and\" ... \"\" \"\" \"\"]\n[960 961 92 ... 0 0 0]\n[\"affirming\" \"or\" \"giving\" ... \"\" \"\" \"\"]\n[963 5 51 ... 0 0 0]\n[\"expressing\" \"agreement\" \"or\" ... \"\" \"\" \"\"]\n[552 965 5 ... 0 0 0]\n[\"expressing\" \"or\" \"consisting\" ... \"\" \"\" \"\"]\n[552 5 967 ... 0 0 0]\n[\"disagreeing\" \"especially\" \"with\" ... \"\" \"\" \"\"]\n[971 27 44 ... 0 0 0]\n[\"inclined\" \"to\" \"accept\" ... \"\" \"\" \"\"]\n[973 9 974 ... 0 0 0]\n[\"tolerating\" \"without\" \"protest\" ... \"\" \"\" \"\"]\n[976 88 977 ... 0 0 0]\n[\"rejecting\" \"or\" \"tending\" ... \"\" \"\" \"\"]\n[978 5 368 ... 0 0 0]\n[\"stopping\" \"to\" \"associate\" ... \"\" \"\" \"\"]\n[979 9 980 ... 0 0 0]\n[\"rejecting\" \"emphatically\" \"\" ... \"\" \"\" \"\"]\n[978 981 0 ... 0 0 0]\n[\"eg\" \"refusing\" \"to\" ... \"\" \"\" \"\"]\n[422 982 9 ... 0 0 0]\n[\"borne\" \"on\" \"the\" ... \"\" \"\" \"\"]\n[985 23 2 ... 0 0 0]\n[\"floating\" \"\" \"\" ... \"\" \"\" \"\"]\n[987 0 0 ... 0 0 0]\n[\"afloat\" \"on\" \"the\" ... \"\" \"\" \"\"]\n[988 23 2 ... 0 0 0]\n[\"borne\" \"up\" \"by\" ... \"\" \"\" \"\"]\n[985 105 69 ... 0 0 0]\n[\"supported\" \"by\" \"water\" ... \"\" \"\" \"\"]\n[990 69 986 ... 0 0 0]\n[\"stuck\" \"in\" \"a\" ... \"\" \"\" \"\"]\n[991 53 97 ... 0 0 0]\n[\"filled\" \"with\" \"fear\" ... \"\" \"\" \"\"]\n[242 44 995 ... 0 0 0]\n[\"suffering\" \"from\" \"acrophobia\" ... \"\" \"\" \"\"]\n[164 15 997 ... 0 0 0]\n[\"abnormally\" \"afraid\" \"of\" ... \"\" \"\" \"\"]\n[464 998 17 ... 0 0 0]\n[\"a\" \"pronunciation\" \"of\" ... \"\" \"\" \"\"]\n[97 1000 17 ... 0 0 0]\n[\"struck\" \"with\" \"fear\" ... \"\" \"\" \"\"]\n[1001 44 995 ... 0 0 0]\n[\"suffering\" \"from\" \"agoraphobia\" ... \"\" \"\" \"\"]\n[164 15 1004 ... 0 0 0]\n[\"abnormally\" \"afraid\" \"of\" ... \"\" \"\" \"\"]\n[464 998 17 ... 0 0 0]\n[\"experiencing\" \"a\" \"sudden\" ... \"\" \"\" \"\"]\n[600 97 1006 ... 0 0 0]\n[\"suffering\" \"from\" \"algophobia\" ... \"\" \"\" \"\"]\n[164 15 1009 ... 0 0 0]\n[\"abnormally\" \"afraid\" \"of\" ... \"\" \"\" \"\"]\n[464 998 17 ... 0 0 0]\n[\"in\" \"fear\" \"or\" ... \"\" \"\" \"\"]\n[53 995 5 ... 0 0 0]\n[\"frightened\" \"into\" \"submission\" ... \"\" \"\" \"\"]\n[1012 40 1013 ... 0 0 0]\n[\"suffering\" \"from\" \"claustrophobia\" ... \"\" \"\" \"\"]\n[164 15 1015 ... 0 0 0]\n[\"abnormally\" \"afraid\" \"of\" ... \"\" \"\" \"\"]\n[464 998 17 ... 0 0 0]\n[\"experiencing\" \"or\" \"showing\" ... \"\" \"\" \"\"]\n[600 5 307 ... 0 0 0]\n[\"made\" \"afraid\" \"\" ... \"\" \"\" \"\"]\n[388 998 0 ... 0 0 0]\n[\"stricken\" \"with\" \"horror\" ... \"\" \"\" \"\"]\n[1017 44 1018 ... 0 0 0]\n[\"reflecting\" \"the\" \"fear\" ... \"\" \"\" \"\"]\n[1019 2 995 ... 0 0 0]\n[\"abnormally\" \"afraid\" \"of\" ... \"\" \"\" \"\"]\n[464 998 17 ... 0 0 0]\n[\"suffering\" \"from\" \"mysophobia\" ... \"\" \"\" \"\"]\n[164 15 1023 ... 0 0 0]\n[\"abnormally\" \"afraid\" \"of\" ... \"\" \"\" \"\"]\n[464 998 17 ... 0 0 0]\n[\"thrown\" \"into\" \"a\" ... \"\" \"\" \"\"]\n[334 40 97 ... 0 0 0]\n[\"so\" \"frightened\" \"as\" ... \"\" \"\" \"\"]\n[1028 1012 46 ... 0 0 0]\n[\"stunned\" \"or\" \"paralyzed\" ... \"\" \"\" \"\"]\n[1029 5 1030 ... 0 0 0]\n[\"petrified\" \"\" \"\" ... \"\" \"\" \"\"]\n[1031 0 0 ... 0 0 0]\n[\"extremely\" \"frightened\" \"\" ... \"\" \"\" \"\"]\n[620 1012 0 ... 0 0 0]\n[\"struck\" \"or\" \"filled\" ... \"\" \"\" \"\"]\n[1001 5 242 ... 0 0 0]\n[\"suffering\" \"from\" \"triskaidekaphobia\" ... \"\" \"\" \"\"]\n[164 15 1032 ... 0 0 0]\n[\"deprived\" \"of\" \"courage\" ... \"\" \"\" \"\"]\n[1033 17 1034 ... 0 0 0]\n[\"having\" \"white\" \"lips\" ... \"\" \"\" \"\"]\n[1 1036 1037 ... 0 0 0]\n[\"suffering\" \"from\" \"xenophobia\" ... \"\" \"\" \"\"]\n[164 15 1038 ... 0 0 0]\n[\"having\" \"abnormal\" \"fear\" ... \"\" \"\" \"\"]\n[1 1039 995 ... 0 0 0]\n[\"oblivious\" \"of\" \"dangers\" ... \"\" \"\" \"\"]\n[1043 17 1044 ... 0 0 0]\n[\"not\" \"recognizing\" \"or\" ... \"\" \"\" \"\"]\n[12 1049 5 ... 0 0 0]\n[\"not\" \"shrinking\" \"from\" ... \"\" \"\" \"\"]\n[12 1051 15 ... 0 0 0]\n[\"not\" \"affected\" \"by\" ... \"\" \"\" \"\"]\n[12 251 69 ... 0 0 0]\n[\"having\" \"or\" \"showing\" ... \"\" \"\" \"\"]\n[1 5 307 ... 0 0 0]\n[\"positive\" \"in\" \"his\" ... \"\" \"\" \"\"]\n[1056 53 1057 ... 0 0 0]\n[\"having\" \"or\" \"showing\" ... \"\" \"\" \"\"]\n[1 5 307 ... 0 0 0]\n[\"showing\" \"a\" \"fighting\" ... \"\" \"\" \"\"]\n[307 97 1061 ... 0 0 0]\n[\"aggressively\" \"and\" \"persistently\" ... \"\" \"\" \"\"]\n[1062 92 1063 ... 0 0 0]\n[\"unsolicited\" \"and\" \"resisted\" ... \"\" \"\" \"\"]\n[1065 92 1066 ... 0 0 0]\n[\"blatantly\" \"aggressive\" \"\" ... \"\" \"\" \"\"]\n[1069 1070 0 ... 0 0 0]\n[\"boisterously\" \"and\" \"noisily\" ... \"\" \"\" \"\"]\n[1071 92 1072 ... 0 0 0]\n[\"living\" \"by\" \"preying\" ... \"\" \"\" \"\"]\n[243 69 1073 ... 0 0 0]\n[\"ready\" \"and\" \"able\" ... \"\" \"\" \"\"]\n[485 92 114 ... 0 0 0]\n[\"full\" \"of\" \"fighting\" ... \"\" \"\" \"\"]\n[479 17 1061 ... 0 0 0]\n[\"defiantly\" \"aggressive\" \"\" ... \"\" \"\" \"\"]\n[1081 1070 0 ... 0 0 0]\n[\"not\" \"aggressive\" \"\" ... \"\" \"\" \"\"]\n[12 1070 0 ... 0 0 0]\n[\"not\" \"given\" \"to\" ... \"\" \"\" \"\"]\n[12 158 9 ... 0 0 0]\n[\"not\" \"forceful\" \"\" ... \"\" \"\" \"\"]\n[12 1083 0 ... 0 0 0]\n[\"troubled\" \"emotionally\" \"and\" ... \"\" \"\" \"\"]\n[1084 1085 92 ... 0 0 0]\n[\"excessively\" \"affected\" \"by\" ... \"\" \"\" \"\"]\n[181 251 69 ... 0 0 0]\n[\"deeply\" \"agitated\" \"especially\" ... \"\" \"\" \"\"]\n[924 1087 27 ... 0 0 0]\n[\"disturbed\" \"psychologically\" \"as\" ... \"\" \"\" \"\"]\n[1088 1089 46 ... 0 0 0]\n[\"marked\" \"by\" \"intense\" ... \"\" \"\" \"\"]\n[321 69 1026 ... 0 0 0]\n[\"excessively\" \"agitated\" \"\" ... \"\" \"\" \"\"]\n[181 1087 0 ... 0 0 0]\n[\"distraught\" \"with\" \"fear\" ... \"\" \"\" \"\"]\n[1093 44 995 ... 0 0 0]\n[\"marked\" \"by\" \"excessive\" ... \"\" \"\" \"\"]\n[321 69 165 ... 0 0 0]\n[\"characterized\" \"by\" \"intense\" ... \"\" \"\" \"\"]\n[190 69 1026 ... 0 0 0]\n[\"appearing\" \"extremely\" \"agitated\" ... \"\" \"\" \"\"]\n[1102 620 1087 ... 0 0 0]\n[\"not\" \"agitated\" \"or\" ... \"\" \"\" \"\"]\n[12 1087 5 ... 0 0 0]\n[\"physically\" \"disturbed\" \"or\" ... \"\" \"\" \"\"]\n[264 1088 5 ... 0 0 0]\n[\"agitated\" \"vigorously\" \"\" ... \"\" \"\" \"\"]\n[1087 445 0 ... 0 0 0]\n[\"in\" \"a\" \"state\" ... \"\" \"\" \"\"]\n[53 97 553 ... 0 0 0]\n[\"moving\" \"with\" \"or\" ... \"\" \"\" \"\"]\n[447 44 5 ... 0 0 0]\n[\"bumped\" \"or\" \"shaken\" ... \"\" \"\" \"\"]\n[1106 5 1107 ... 0 0 0]\n[\"shaken\" \"into\" \"waves\" ... \"\" \"\" \"\"]\n[1107 40 1109 ... 0 0 0]\n[\"in\" \"constant\" \"agitation\" ... \"\" \"\" \"\"]\n[53 1112 1092 ... 0 0 0]\n[\"set\" \"into\" \"a\" ... \"\" \"\" \"\"]\n[472 40 97 ... 0 0 0]\n[\"not\" \"physically\" \"disturbed\" ... \"\" \"\" \"\"]\n[12 264 1088 ... 0 0 0]\n[\"not\" \"turbulent\" \"\" ... \"\" \"\" \"\"]\n[12 1117 0 ... 0 0 0]\n[\"not\" \"agitated\" \"by\" ... \"\" \"\" \"\"]\n[12 1087 69 ... 0 0 0]\n[\"conforming\" \"to\" \"your\" ... \"\" \"\" \"\"]\n[315 9 63 ... 0 0 0]\n[\"not\" \"to\" \"your\" ... \"\" \"\" \"\"]\n[12 9 63 ... 0 0 0]\n[\"causing\" \"irritation\" \"or\" ... \"\" \"\" \"\"]\n[520 1121 5 ... 0 0 0]\n[\"sharply\" \"disagreeable\" \"\" ... \"\" \"\" \"\"]\n[1123 1124 0 ... 0 0 0]\n[\"rigorous\" \"\" \"\" ... \"\" \"\" \"\"]\n[1125 0 0 ... 0 0 0]\n[\"extremely\" \"irritating\" \"to\" ... \"\" \"\" \"\"]\n[620 1126 9 ... 0 0 0]\n[\"distasteful\" \"\" \"\" ... \"\" \"\" \"\"]\n[1128 0 0 ... 0 0 0]\n[\"operating\" \"from\" \"or\" ... \"\" \"\" \"\"]\n[1129 15 5 ... 0 0 0]\n[\"operating\" \"between\" \"or\" ... \"\" \"\" \"\"]\n[1129 1134 5 ... 0 0 0]\n[\"operating\" \"from\" \"or\" ... \"\" \"\" \"\"]\n[1129 15 5 ... 0 0 0]\n[\"engaged\" \"in\" \"or\" ... \"\" \"\" \"\"]\n[469 53 5 ... 0 0 0]\n[\"carefully\" \"observant\" \"or\" ... \"\" \"\" \"\"]\n[889 1143 5 ... 0 0 0]\n[\"on\" \"the\" \"lookout\" ... \"\" \"\" \"\"]\n[23 2 1145 ... 0 0 0]\n[\"not\" \"to\" \"be\" ... \"\" \"\" \"\"]\n[12 9 59 ... 0 0 0]\n[\"fully\" \"alert\" \"and\" ... \"\" \"\" \"\"]\n[1148 1149 92 ... 0 0 0]\n[\"always\" \"watchful\" \"\" ... \"\" \"\" \"\"]\n[1151 1150 0 ... 0 0 0]\n[\"not\" \"alert\" \"to\" ... \"\" \"\" \"\"]\n[12 1149 9 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"relating\" \"to\" \"solving\" ... \"\" \"\" \"\"]\n[363 9 1160 ... 0 0 0]\n[\"transferable\" \"to\" \"another\" ... \"\" \"\" \"\"]\n[1163 9 1164 ... 0 0 0]\n[\"that\" \"can\" \"be\" ... \"\" \"\" \"\"]\n[277 173 59 ... 0 0 0]\n[\"legally\" \"transferable\" \"to\" ... \"\" \"\" \"\"]\n[1167 1163 9 ... 0 0 0]\n[\"incapable\" \"of\" \"being\" ... \"\" \"\" \"\"]\n[130 17 36 ... 0 0 0]\n[\"not\" \"capable\" \"of\" ... \"\" \"\" \"\"]\n[12 109 17 ... 0 0 0]\n[\"cannot\" \"be\" \"bought\" ... \"\" \"\" \"\"]\n[1173 59 1174 ... 0 0 0]\n[\"incapable\" \"of\" \"being\" ... \"\" \"\" \"\"]\n[130 17 36 ... 0 0 0]\n[\"possessing\" \"life\" \"\" ... \"\" \"\" \"\"]\n[1176 57 0 ... 0 0 0]\n[\"showing\" \"signs\" \"of\" ... \"\" \"\" \"\"]\n[307 1177 17 ... 0 0 0]\n[\"not\" \"stillborn\" \"\" ... \"\" \"\" \"\"]\n[12 1178 0 ... 0 0 0]\n[\"capable\" \"of\" \"life\" ... \"\" \"\" \"\"]\n[109 17 57 ... 0 0 0]\n[\"manifesting\" \"or\" \"characteristic\" ... \"\" \"\" \"\"]\n[859 5 1179 ... 0 0 0]\n[\"no\" \"longer\" \"having\" ... \"\" \"\" \"\"]\n[476 477 1 ... 0 0 0]\n[\"dead\" \"\" \"\" ... \"\" \"\" \"\"]\n[1183 0 0 ... 0 0 0]\n[\"murdered\" \"by\" \"surprise\" ... \"\" \"\" \"\"]\n[1184 69 1185 ... 0 0 0]\n[\"destitute\" \"of\" \"blood\" ... \"\" \"\" \"\"]\n[1189 17 1190 ... 0 0 0]\n[\"having\" \"irreversible\" \"loss\" ... \"\" \"\" \"\"]\n[1 1192 617 ... 0 0 0]\n[\"appearing\" \"dead\" \"\" ... \"\" \"\" \"\"]\n[1102 1183 0 ... 0 0 0]\n[\"not\" \"breathing\" \"or\" ... \"\" \"\" \"\"]\n[12 62 5 ... 0 0 0]\n[\"lacking\" \"the\" \"warmth\" ... \"\" \"\" \"\"]\n[83 2 1200 ... 0 0 0]\n[\"abbreviation\" \"for\" \"dead\" ... \"\" \"\" \"\"]\n[1201 154 1183 ... 0 0 0]\n[\"having\" \"the\" \"physical\" ... \"\" \"\" \"\"]\n[1 2 138 ... 0 0 0]\n[\"having\" \"ceased\" \"to\" ... \"\" \"\" \"\"]\n[1 1206 9 ... 0 0 0]\n[\"marked\" \"for\" \"certain\" ... \"\" \"\" \"\"]\n[321 154 1209 ... 0 0 0]\n[\"put\" \"to\" \"death\" ... \"\" \"\" \"\"]\n[406 9 61 ... 0 0 0]\n[\"killed\" \"in\" \"battle\" ... \"\" \"\" \"\"]\n[1211 53 1212 ... 0 0 0]\n[\"having\" \"died\" \"recently\" ... \"\" \"\" \"\"]\n[1 1213 1214 ... 0 0 0]\n[\"deprived\" \"of\" \"life\" ... \"\" \"\" \"\"]\n[1033 17 57 ... 0 0 0]\n[\"no\" \"longer\" \"living\" ... \"\" \"\" \"\"]\n[476 477 243 ... 0 0 0]\n[\"killed\" \"unlawfully\" \"\" ... \"\" \"\" \"\"]\n[1211 1215 0 ... 0 0 0]\n[\"not\" \"capable\" \"of\" ... \"\" \"\" \"\"]\n[12 109 17 ... 0 0 0]\n[\"killed\" \"\" \"\" ... \"\" \"\" \"\"]\n[1211 0 0 ... 0 0 0]\n[\"slain\\'\" \"is\" \"formal\" ... \"\" \"\" \"\"]\n[1217 411 947 ... 0 0 0]\n[\"showing\" \"no\" \"signs\" ... \"\" \"\" \"\"]\n[307 476 1177 ... 0 0 0]\n[\"not\" \"liveborn\" \"\" ... \"\" \"\" \"\"]\n[12 1221 0 ... 0 0 0]\n[\"as\" \"lifeless\" \"as\" ... \"\" \"\" \"\"]\n[46 1222 46 ... 0 0 0]\n[\"producing\" \"a\" \"secretion\" ... \"\" \"\" \"\"]\n[568 97 1223 ... 0 0 0]\n[\"producing\" \"a\" \"clear\" ... \"\" \"\" \"\"]\n[568 97 1227 ... 0 0 0]\n[\"important\" \"in\" \"regulating\" ... \"\" \"\" \"\"]\n[1228 53 1229 ... 0 0 0]\n[\"rising\" \"to\" \"the\" ... \"\" \"\" \"\"]\n[1230 9 2 ... 0 0 0]\n[\"rising\" \"naturally\" \"in\" ... \"\" \"\" \"\"]\n[1230 961 53 ... 0 0 0]\n[\"exerting\" \"force\" \"or\" ... \"\" \"\" \"\"]\n[566 45 5 ... 0 0 0]\n[\"of\" \"a\" \"ball\" ... \"\" \"\" \"\"]\n[17 97 1238 ... 0 0 0]\n[\"in\" \"its\" \"natural\" ... \"\" \"\" \"\"]\n[53 76 949 ... 0 0 0]\n[\"not\" \"mined\" \"or\" ... \"\" \"\" \"\"]\n[12 1239 5 ... 0 0 0]\n[\"not\" \"showing\" \"characteristics\" ... \"\" \"\" \"\"]\n[12 307 360 ... 0 0 0]\n[\"no\" \"longer\" \"exerting\" ... \"\" \"\" \"\"]\n[476 477 566 ... 0 0 0]\n[\"being\" \"out\" \"or\" ... \"\" \"\" \"\"]\n[36 543 5 ... 0 0 0]\n[\"not\" \"having\" \"the\" ... \"\" \"\" \"\"]\n[12 1 2 ... 0 0 0]\n[\"\\\"a\" \"ball\" \"that\" ... \"\" \"\" \"\"]\n[1246 1238 277 ... 0 0 0]\n[\"arranged\" \"in\" \"order\" ... \"\" \"\" \"\"]\n[1249 53 1114 ... 0 0 0]\n[\"alphabetically\" \"arranged\" \"\" ... \"\" \"\" \"\"]\n[1252 1249 0 ... 0 0 0]\n[\"having\" \"been\" \"put\" ... \"\" \"\" \"\"]\n[1 1253 406 ... 0 0 0]\n[\"not\" \"alphabetic\" \"\" ... \"\" \"\" \"\"]\n[12 1255 0 ... 0 0 0]\n[\"naked\" \"and\" \"blind\" ... \"\" \"\" \"\"]\n[1256 92 1257 ... 0 0 0]\n[\"covered\" \"with\" \"down\" ... \"\" \"\" \"\"]\n[711 44 1259 ... 0 0 0]\n[\"capable\" \"of\" \"leaving\" ... \"\" \"\" \"\"]\n[109 17 1261 ... 0 0 0]\n[\"showing\" \"unselfish\" \"concern\" ... \"\" \"\" \"\"]\n[307 1266 1267 ... 0 0 0]\n[\"limited\" \"to\" \"or\" ... \"\" \"\" \"\"]\n[1269 9 5 ... 0 0 0]\n[\"absorbed\" \"in\" \"your\" ... \"\" \"\" \"\"]\n[140 53 63 ... 0 0 0]\n[\"having\" \"more\" \"than\" ... \"\" \"\" \"\"]\n[1 170 171 ... 0 0 0]\n[\"having\" \"two\" \"purposes\" ... \"\" \"\" \"\"]\n[1 1275 1276 ... 0 0 0]\n[\"twofold\" \"\" \"\" ... \"\" \"\" \"\"]\n[1277 0 0 ... 0 0 0]\n[\"capable\" \"of\" \"being\" ... \"\" \"\" \"\"]\n[109 17 36 ... 0 0 0]\n[\"resembling\" \"an\" \"oracle\" ... \"\" \"\" \"\"]\n[176 18 1281 ... 0 0 0]\n[\"ironically\" \"ambiguous\" \"\" ... \"\" \"\" \"\"]\n[1283 1284 0 ... 0 0 0]\n[\"having\" \"many\" \"values\" ... \"\" \"\" \"\"]\n[1 758 1285 ... 0 0 0]\n[\"of\" \"words\" \"\" ... \"\" \"\" \"\"]\n[17 1288 0 ... 0 0 0]\n[\"having\" \"many\" \"meanings\" ... \"\" \"\" \"\"]\n[1 758 1286 ... 0 0 0]\n[\"ambiguous\" \"\" \"\" ... \"\" \"\" \"\"]\n[1284 0 0 ... 0 0 0]\n[\"having\" \"or\" \"exhibiting\" ... \"\" \"\" \"\"]\n[1 5 258 ... 0 0 0]\n[\"having\" \"only\" \"one\" ... \"\" \"\" \"\"]\n[1 183 172 ... 0 0 0]\n[\"having\" \"a\" \"strong\" ... \"\" \"\" \"\"]\n[1 97 1292 ... 0 0 0]\n[\"marked\" \"by\" \"aggressive\" ... \"\" \"\" \"\"]\n[321 69 1070 ... 0 0 0]\n[\"desiring\" \"or\" \"striving\" ... \"\" \"\" \"\"]\n[1297 5 1298 ... 0 0 0]\n[\"strongly\" \"motivated\" \"to\" ... \"\" \"\" \"\"]\n[1299 1300 9 ... 0 0 0]\n[\"unfulfilled\" \"or\" \"frustrated\" ... \"\" \"\" \"\"]\n[1302 5 1303 ... 0 0 0]\n[\"excessively\" \"ambitious\" \"\" ... \"\" \"\" \"\"]\n[181 1305 0 ... 0 0 0]\n[\"having\" \"little\" \"desire\" ... \"\" \"\" \"\"]\n[1 223 930 ... 0 0 0]\n[\"lacking\" \"or\" \"characterized\" ... \"\" \"\" \"\"]\n[83 5 190 ... 0 0 0]\n[\"lazy\" \"\" \"\" ... \"\" \"\" \"\"]\n[1306 0 0 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"more\" \"than\" \"enough\" ... \"\" \"\" \"\"]\n[170 171 1313 ... 0 0 0]\n[\"having\" \"the\" \"normally\" ... \"\" \"\" \"\"]\n[1 2 1315 ... 0 0 0]\n[\"more\" \"than\" \"adequate\" ... \"\" \"\" \"\"]\n[170 171 685 ... 0 0 0]\n[\"having\" \"ample\" \"fabric\" ... \"\" \"\" \"\"]\n[1 1317 1318 ... 0 0 0]\n[\"deficient\" \"in\" \"amount\" ... \"\" \"\" \"\"]\n[246 53 687 ... 0 0 0]\n[\"lacking\" \"in\" \"amplitude\" ... \"\" \"\" \"\"]\n[83 53 1321 ... 0 0 0]\n[\"extremely\" \"scanty\" \"\" ... \"\" \"\" \"\"]\n[620 1322 0 ... 0 0 0]\n[\"providing\" \"only\" \"bare\" ... \"\" \"\" \"\"]\n[653 183 1323 ... 0 0 0]\n[\"barely\" \"satisfying\" \"a\" ... \"\" \"\" \"\"]\n[1325 907 97 ... 0 0 0]\n[\"contemptibly\" \"small\" \"in\" ... \"\" \"\" \"\"]\n[1327 797 53 ... 0 0 0]\n[\"characterized\" \"by\" \"or\" ... \"\" \"\" \"\"]\n[190 69 5 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"characterized\" \"by\" \"destructive\" ... \"\" \"\" \"\"]\n[190 69 1331 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"of\" \"valleys\" \"and\" ... \"\" \"\" \"\"]\n[17 1333 92 ... 0 0 0]\n[\"progressing\" \"in\" \"a\" ... \"\" \"\" \"\"]\n[508 53 97 ... 0 0 0]\n[\"of\" \"valleys\" \"and\" ... \"\" \"\" \"\"]\n[17 1333 92 ... 0 0 0]\n[\"running\" \"in\" \"the\" ... \"\" \"\" \"\"]\n[1340 53 2 ... 0 0 0]\n[\"not\" \"astigmatic\" \"\" ... \"\" \"\" \"\"]\n[12 1341 0 ... 0 0 0]\n[\"of\" \"or\" \"relating\" ... \"\" \"\" \"\"]\n[17 5 363 ... 0 0 0]\n[\"sloping\" \"downward\" \"away\" ... \"\" \"\" \"\"]\n[1352 1353 14 ... 0 0 0]\n[\"sloping\" \"downward\" \"toward\" ... \"\" \"\" \"\"]\n[1352 1353 22 ... 0 0 0]\n[\"migrating\" \"from\" \"the\" ... \"\" \"\" \"\"]\n[1358 15 2 ... 0 0 0]\n[\"migrating\" \"from\" \"fresh\" ... \"\" \"\" \"\"]\n[1358 15 1360 ... 0 0 0]\n[\"migratory\" \"between\" \"fresh\" ... \"\" \"\" \"\"]\n[1362 1134 1360 ... 0 0 0]\n[\"of\" \"an\" \"air\" ... \"\" \"\" \"\"]\n[17 18 894 ... 0 0 0]\n[\"rising\" \"especially\" \"up\" ... \"\" \"\" \"\"]\n[1230 27 105 ... 0 0 0]\n[\"of\" \"an\" \"air\" ... \"\" \"\" \"\"]\n[17 18 894 ... 0 0 0]\n[\"moving\" \"downward\" \"or\" ... \"\" \"\" \"\"]\n[447 1353 5 ... 0 0 0]\n[\"a\" \"stage\" \"in\" ... \"\" \"\" \"\"]\n[97 1370 53 ... 0 0 0]\n[\"fixation\" \"at\" \"this\" ... \"\" \"\" \"\"]\n[1377 66 1378 ... 0 0 0]\n[\"a\" \"stage\" \"in\" ... \"\" \"\" \"\"]\n[97 1370 53 ... 0 0 0]\n[\"fixation\" \"at\" \"this\" ... \"\" \"\" \"\"]\n[1377 66 1378 ... 0 0 0]\n[\"of\" \"a\" \"circuit\" ... \"\" \"\" \"\"]\n[17 97 1389 ... 0 0 0]\n[\"of\" \"a\" \"circuit\" ... \"\" \"\" \"\"]\n[17 97 1389 ... 0 0 0]\n[\"of\" \"a\" \"proposition\" ... \"\" \"\" \"\"]\n[17 97 1396 ... 0 0 0]\n[\"of\" \"a\" \"proposition\" ... \"\" \"\" \"\"]\n[17 97 1396 ... 0 0 0]\n[\"expressing\" \"a\" \"grammatical\" ... \"\" \"\" \"\"]\n[552 97 1402 ... 0 0 0]\n[\"relating\" \"to\" \"or\" ... \"\" \"\" \"\"]\n[363 9 5 ... 0 0 0]\n[\"systematic\" \"combining\" \"of\" ... \"\" \"\" \"\"]\n[1414 1415 17 ... 0 0 0]\n[\"forming\" \"derivative\" \"or\" ... \"\" \"\" \"\"]\n[1418 1419 5 ... 0 0 0]\n[\"using\" \"or\" \"skilled\" ... \"\" \"\" \"\"]\n[898 5 1423 ... 0 0 0]\n[\"involving\" \"or\" \"of\" ... \"\" \"\" \"\"]\n[527 5 17 ... 0 0 0]\n[\"characterized\" \"by\" \"inflections\" ... \"\" \"\" \"\"]\n[190 69 1426 ... 0 0 0]\n[\"characterized\" \"by\" \"inflections\" ... \"\" \"\" \"\"]\n[190 69 1426 ... 0 0 0]\n[\"consisting\" \"of\" \"carpels\" ... \"\" \"\" \"\"]\n[967 17 1429 ... 0 0 0]\n[\"consisting\" \"of\" \"united\" ... \"\" \"\" \"\"]\n[967 17 697 ... 0 0 0]\n[\"feeling\" \"or\" \"showing\" ... \"\" \"\" \"\"]\n[1432 5 307 ... 0 0 0]\n[\"incited\" \"especially\" \"deliberately\" ... \"\" \"\" \"\"]\n[1434 27 1435 ... 0 0 0]\n[\"marked\" \"by\" \"extreme\" ... \"\" \"\" \"\"]\n[321 69 230 ... 0 0 0]\n[\"marked\" \"by\" \"anger\" ... \"\" \"\" \"\"]\n[321 69 1433 ... 0 0 0]\n[\"characterized\" \"by\" \"anger\" ... \"\" \"\" \"\"]\n[190 69 1433 ... 0 0 0]\n[\"very\" \"angry\" \"\" ... \"\" \"\" \"\"]\n[451 1438 0 ... 0 0 0]\n[\"roused\" \"to\" \"anger\" ... \"\" \"\" \"\"]\n[1439 9 1433 ... 0 0 0]\n[\"angered\" \"at\" \"something\" ... \"\" \"\" \"\"]\n[1440 66 11 ... 0 0 0]\n[\"feeling\" \"or\" \"showing\" ... \"\" \"\" \"\"]\n[1432 5 307 ... 0 0 0]\n[\"furiously\" \"angry\" \"\" ... \"\" \"\" \"\"]\n[1442 1438 0 ... 0 0 0]\n[\"showing\" \"scarcely\" \"suppressed\" ... \"\" \"\" \"\"]\n[307 1443 1444 ... 0 0 0]\n[\"vehemently\" \"incensed\" \"and\" ... \"\" \"\" \"\"]\n[1445 1446 92 ... 0 0 0]\n[\"not\" \"angry\" \"\" ... \"\" \"\" \"\"]\n[12 1438 0 ... 0 0 0]\n[\"full\" \"of\" \"or\" ... \"\" \"\" \"\"]\n[479 17 5 ... 0 0 0]\n[\"marked\" \"by\" \"strong\" ... \"\" \"\" \"\"]\n[321 69 1292 ... 0 0 0]\n"
+    }
+   ],
+   "source": [
+    "for x, y in dataset:\n",
+    "    words = tf.keras.backend.argmax(y, axis=-1)\n",
+    "    words = words.numpy().tolist()\n",
+    "    print(output2string([words], num2word))"
    ]
   },
   {
