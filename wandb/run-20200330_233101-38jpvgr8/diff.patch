diff --git a/__pycache__/utils.cpython-37.pyc b/__pycache__/utils.cpython-37.pyc
index e78db15..0e1db5e 100644
Binary files a/__pycache__/utils.cpython-37.pyc and b/__pycache__/utils.cpython-37.pyc differ
diff --git a/bin, but it's python/__pycache__/structs.cpython-37.pyc b/bin, but it's python/__pycache__/structs.cpython-37.pyc
index cc4806e..852d7fe 100644
Binary files a/bin, but it's python/__pycache__/structs.cpython-37.pyc and b/bin, but it's python/__pycache__/structs.cpython-37.pyc differ
diff --git a/bin, but it's python/__pycache__/utils.cpython-37.pyc b/bin, but it's python/__pycache__/utils.cpython-37.pyc
index ec32701..1d7180a 100644
Binary files a/bin, but it's python/__pycache__/utils.cpython-37.pyc and b/bin, but it's python/__pycache__/utils.cpython-37.pyc differ
diff --git a/dataProcessing.ipynb b/dataProcessing.ipynb
index d9e550f..6eff425 100644
--- a/dataProcessing.ipynb
+++ b/dataProcessing.ipynb
@@ -1,27 +1,4 @@
 {
- "nbformat": 4,
- "nbformat_minor": 2,
- "metadata": {
-  "language_info": {
-   "name": "python",
-   "codemirror_mode": {
-    "name": "ipython",
-    "version": 3
-   },
-   "version": "3.7.4-final"
-  },
-  "orig_nbformat": 2,
-  "file_extension": ".py",
-  "mimetype": "text/x-python",
-  "name": "python",
-  "npconvert_exporter": "python",
-  "pygments_lexer": "ipython3",
-  "version": 3,
-  "kernelspec": {
-   "name": "python37464bitprojenvvenv5183e90ff64f49ee83b8a29c549cc789",
-   "display_name": "Python 3.7.4 64-bit ('projenv': venv)"
-  }
- },
  "cells": [
   {
    "cell_type": "code",
@@ -29,17 +6,17 @@
    "metadata": {},
    "outputs": [
     {
-     "name": "stdout",
      "output_type": "stream",
+     "name": "stdout",
      "text": "Successfully logged in to Weights & Biases!\nwandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\DS/.netrc\n"
     },
     {
+     "output_type": "display_data",
      "data": {
-      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/f2utsmym\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/f2utsmym</a><br/>\n            ",
-      "text/plain": "<IPython.core.display.HTML object>"
+      "text/plain": "<IPython.core.display.HTML object>",
+      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/zxs20v9o\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/zxs20v9o</a><br/>\n            "
      },
-     "metadata": {},
-     "output_type": "display_data"
+     "metadata": {}
     }
    ],
    "source": [
@@ -55,7 +32,8 @@
     "import wandb\n",
     "from wandb.keras import WandbCallback\n",
     "wandb.init(project=\"lstm-autoencoder-esc190\")\n",
-    "config = wandb.config\n"
+    "config = wandb.config\n",
+    ""
    ]
   },
   {
@@ -64,8 +42,8 @@
    "metadata": {},
    "outputs": [
     {
-     "name": "stdout",
      "output_type": "stream",
+     "name": "stdout",
      "text": "Size of vocabulary: 117659\nLongest definition (words): 54\nNumber of definitions: 135959\nSize of definition vocabulary: 46948\n(135959, 54)\n"
     }
    ],
@@ -92,21 +70,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 3,
    "metadata": {},
-   "outputs": [
-    {
-     "ename": "NameError",
-     "evalue": "name 'vocab_size' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[1;32m<ipython-input-1-2ddc14c4efd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_zero\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_zero\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mencodingLSTM1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'vocab_size' is not defined"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "from tensorflow.keras.models import Model, Sequential\n",
     "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM, RepeatVector, TimeDistributed, Lambda\n",
@@ -173,15 +139,20 @@
     "denseboi = TimeDistributed(Dense(100, activation=\"relu\"))(decodingLSTM2)\n",
     "finalDense = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(denseboi)\n",
     "output = finalDense\n",
-    "#creating optimizers and loss\n",
-    "\n"
+    "#creating optimizers and loss"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 4,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "output_type": "stream",
+     "name": "stdout",
+     "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, None, 64)     3004736     input_1[0][0]                    \n__________________________________________________________________________________________________\ntf_op_layer_NotEqual (TensorFlo [(None, None)]       0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlstm (LSTM)                     (None, None, 64)     33024       embedding[0][0]                  \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   (None, 32)           12416       lstm[0][0]                       \n__________________________________________________________________________________________________\nrepeat_vector (RepeatVector)    (None, 54, 32)       0           lstm_1[0][0]                     \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   (None, 54, 32)       8320        repeat_vector[0][0]              \n__________________________________________________________________________________________________\nlstm_3 (LSTM)                   (None, 54, 64)       24832       lstm_2[0][0]                     \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, 54, 100)      6500        lstm_3[0][0]                     \n__________________________________________________________________________________________________\ntime_distributed_1 (TimeDistrib (None, 54, 46948)    4741748     time_distributed[0][0]           \n==================================================================================================\nTotal params: 7,831,576\nTrainable params: 7,831,576\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
+    }
+   ],
    "source": [
     "model = Model(inputs=inputs, outputs=output)\n",
     "optimizer = Adam(learning_rate = 0.0003)\n",
@@ -257,20 +228,28 @@
    "outputs": [
     {
      "data": {
-      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/l6c7og3x\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/l6c7og3x</a><br/>\n            ",
-      "text/plain": "<IPython.core.display.HTML object>"
+      "text/html": [
+       "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/l6c7og3x\" target=\"_blank\">https://app.wandb.ai/epicrunze/lstm-autoencoder-esc190/runs/l6c7og3x</a><br/>\n            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
      },
      "metadata": {},
-     "output_type": "display_data"
+     "output_type": "execute_result"
     },
     {
      "name": "stdout",
      "output_type": "stream",
-     "text": "Train for 8498 steps\nEpoch 1/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.4075 - accuracy: 0.5190\nEpoch 00001: saving model to 32vec.5.weights.01.h5\n8498/8498 [==============================] - 2478s 292ms/step - loss: 0.4075 - accuracy: 0.5190\nEpoch 2/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.5259\nEpoch 00002: saving model to 32vec.5.weights.02.h5\n8498/8498 [==============================] - 2362s 278ms/step - loss: 0.3949 - accuracy: 0.5259\nEpoch 3/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.5304\nEpoch 00003: saving model to 32vec.5.weights.03.h5\n8498/8498 [==============================] - 2356s 277ms/step - loss: 0.3877 - accuracy: 0.5304\nEpoch 4/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.5357\nEpoch 00004: saving model to 32vec.5.weights.04.h5\n8498/8498 [==============================] - 2365s 278ms/step - loss: 0.3809 - accuracy: 0.5357\nEpoch 5/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.5396\nEpoch 00005: saving model to 32vec.5.weights.05.h5\n8498/8498 [==============================] - 2356s 277ms/step - loss: 0.3756 - accuracy: 0.5396\nEpoch 6/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.5443\nEpoch 00006: saving model to 32vec.5.weights.06.h5\n8498/8498 [==============================] - 2361s 278ms/step - loss: 0.3694 - accuracy: 0.5443\nEpoch 7/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3644 - accuracy: 0.5485\nEpoch 00007: saving model to 32vec.5.weights.07.h5\n8498/8498 [==============================] - 2362s 278ms/step - loss: 0.3644 - accuracy: 0.5485\nEpoch 8/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.5527\nEpoch 00008: saving model to 32vec.5.weights.08.h5\n8498/8498 [==============================] - 2354s 277ms/step - loss: 0.3597 - accuracy: 0.5527\n"
+     "text": [
+      "Train for 8498 steps\nEpoch 1/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.4075 - accuracy: 0.5190\nEpoch 00001: saving model to 32vec.5.weights.01.h5\n8498/8498 [==============================] - 2478s 292ms/step - loss: 0.4075 - accuracy: 0.5190\nEpoch 2/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.5259\nEpoch 00002: saving model to 32vec.5.weights.02.h5\n8498/8498 [==============================] - 2362s 278ms/step - loss: 0.3949 - accuracy: 0.5259\nEpoch 3/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.5304\nEpoch 00003: saving model to 32vec.5.weights.03.h5\n8498/8498 [==============================] - 2356s 277ms/step - loss: 0.3877 - accuracy: 0.5304\nEpoch 4/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.5357\nEpoch 00004: saving model to 32vec.5.weights.04.h5\n8498/8498 [==============================] - 2365s 278ms/step - loss: 0.3809 - accuracy: 0.5357\nEpoch 5/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.5396\nEpoch 00005: saving model to 32vec.5.weights.05.h5\n8498/8498 [==============================] - 2356s 277ms/step - loss: 0.3756 - accuracy: 0.5396\nEpoch 6/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.5443\nEpoch 00006: saving model to 32vec.5.weights.06.h5\n8498/8498 [==============================] - 2361s 278ms/step - loss: 0.3694 - accuracy: 0.5443\nEpoch 7/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3644 - accuracy: 0.5485\nEpoch 00007: saving model to 32vec.5.weights.07.h5\n8498/8498 [==============================] - 2362s 278ms/step - loss: 0.3644 - accuracy: 0.5485\nEpoch 8/8\n8497/8498 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.5527\nEpoch 00008: saving model to 32vec.5.weights.08.h5\n8498/8498 [==============================] - 2354s 277ms/step - loss: 0.3597 - accuracy: 0.5527\n"
+     ]
     },
     {
      "data": {
-      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x24340e51c48>"
+      "text/plain": [
+       "<tensorflow.python.keras.callbacks.History at 0x24340e51c48>"
+      ]
      },
      "execution_count": 17,
      "metadata": {},
@@ -298,5 +277,28 @@
    "outputs": [],
    "source": []
   }
- ]
+ ],
+ "metadata": {
+  "language_info": {
+   "name": "python",
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "version": "3.7.4-final"
+  },
+  "orig_nbformat": 2,
+  "file_extension": ".py",
+  "mimetype": "text/x-python",
+  "name": "python",
+  "npconvert_exporter": "python",
+  "pygments_lexer": "ipython3",
+  "version": 3,
+  "kernelspec": {
+   "name": "python37464bitprojenvvenv5183e90ff64f49ee83b8a29c549cc789",
+   "display_name": "Python 3.7.4 64-bit ('projenv': venv)"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 2
 }
\ No newline at end of file
diff --git a/universalSentenceEmbedding.ipynb b/universalSentenceEmbedding.ipynb
index 1a8c1ab..06c110d 100644
--- a/universalSentenceEmbedding.ipynb
+++ b/universalSentenceEmbedding.ipynb
@@ -7,7 +7,8 @@
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
-   }
+   },
+   "version": "3.7.4-final"
   },
   "orig_nbformat": 2,
   "file_extension": ".py",
@@ -15,14 +16,32 @@
   "name": "python",
   "npconvert_exporter": "python",
   "pygments_lexer": "ipython3",
-  "version": 3
+  "version": 3,
+  "kernelspec": {
+   "name": "python37464bitprojenvvenv5183e90ff64f49ee83b8a29c549cc789",
+   "display_name": "Python 3.7.4 64-bit ('projenv': venv)"
+  }
  },
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 1,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "output_type": "stream",
+     "name": "stdout",
+     "text": "Successfully logged in to Weights & Biases!\nwandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\DS/.netrc\n"
+    },
+    {
+     "output_type": "display_data",
+     "data": {
+      "text/plain": "<IPython.core.display.HTML object>",
+      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/h4au4ybi\" target=\"_blank\">https://app.wandb.ai/epicrunze/USE%2Bdecoder-esc190/runs/h4au4ybi</a><br/>\n            "
+     },
+     "metadata": {}
+    }
+   ],
    "source": [
     "import numpy as np \n",
     "import tensorflow as tf \n",
@@ -35,15 +54,22 @@
     "!wandb login \"41c25b4fc8e96d4ae0d96e0abd4d69787a6ea35f\"\n",
     "import wandb\n",
     "from wandb.keras import WandbCallback\n",
-    "wandb.init(project=\"lstm-autoencoder-esc190\")\n",
-    "config = wandb.config\n"
+    "wandb.init(project=\"USE+decoder-esc190\")\n",
+    "config = wandb.config\n",
+    ""
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 2,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "output_type": "stream",
+     "name": "stdout",
+     "text": "Size of vocabulary: 117659\nLongest definition (words): 54\nNumber of definitions: 135959\nSize of definition vocabulary: 46948\n(135959, 54)\n"
+    }
+   ],
    "source": [
     "data_dir = \"data_wordnet\"\n",
     "data = utils.read_dir(data_dir)\n",
@@ -64,6 +90,146 @@
     "\n",
     "print(x_train.shape)"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import tensorflow_hub as hub\n",
+    "#creating embeddings from definitions\n",
+    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "metadata": {},
+   "outputs": [
+    {
+     "output_type": "stream",
+     "name": "stdout",
+     "text": "tf.Tensor(\n[[ 4.24174629e-02 -9.66826454e-02  2.59118378e-02  2.51377188e-02\n  -3.38306800e-02  6.16692975e-02 -4.99003120e-02 -2.38847770e-02\n   7.11890459e-02 -5.52524365e-02  1.85309332e-02  3.71509939e-02\n   8.33838508e-02 -6.89747110e-02  5.74608985e-03 -9.52255428e-02\n   2.43185442e-02 -6.85690390e-03  9.10456255e-02 -4.10292037e-02\n   1.03226654e-01 -3.45471539e-02 -7.52054974e-02  9.22519900e-03\n  -2.66002063e-02  3.00528556e-02 -2.70382278e-02 -4.01278660e-02\n  -4.01715003e-02  2.31434312e-02 -2.35817228e-02  1.34604163e-02\n  -5.54688908e-02 -1.01312054e-02  3.66086848e-02 -1.36805940e-02\n   5.50382137e-02 -4.02770378e-02  6.40252084e-02 -2.49756966e-02\n   4.66904528e-02  1.04535669e-02  4.87416834e-02 -4.70638722e-02\n  -6.49589896e-02 -1.58786606e-02  1.60771568e-04  5.48374690e-02\n   6.34461036e-03  2.69146655e-02  5.56217954e-02  5.74246012e-02\n   3.05497833e-02 -6.20094202e-02  2.69393958e-02  4.03088592e-02\n  -6.72144815e-02  3.67127843e-02 -9.07467082e-02  9.52368975e-03\n  -1.42075988e-02  2.35202024e-03 -7.00183585e-02 -8.06204453e-02\n  -1.77158918e-02 -5.98998778e-02  1.17027014e-02  6.11600131e-02\n  -9.19129699e-03 -1.41731240e-02  2.83338297e-02  7.02705309e-02\n  -6.20348006e-02 -3.83545347e-02 -3.99473868e-02 -2.38129608e-02\n   5.75753953e-03 -4.14896943e-02  3.46907899e-02  7.74274617e-02\n   2.96490230e-02 -1.82914070e-03 -8.92494321e-02 -2.12321002e-02\n   7.30503649e-02  5.95796891e-02 -1.04614682e-02 -7.13172033e-02\n   6.88673034e-02  1.40907206e-02  3.01116202e-02 -2.50727516e-02\n  -8.94334391e-02 -1.10338060e-02 -3.63470204e-02 -2.87777111e-02\n  -6.12492040e-02  7.36634135e-02 -2.09526718e-02 -1.00403070e-01\n  -1.20081566e-03  2.84682885e-02 -4.98605967e-02  1.71028487e-02\n  -1.69033762e-02 -2.62924396e-02  2.91928202e-02 -5.19951843e-02\n   1.40799433e-02  4.83017266e-02  4.21576984e-02  6.78774416e-02\n   5.24122119e-02 -9.62664781e-05 -2.42049731e-02 -2.24254224e-02\n   4.04517502e-02  6.68532029e-03 -8.05000216e-02  4.66432795e-02\n  -3.31769721e-03 -3.31790484e-02  2.07441542e-02  1.51973171e-02\n   2.49127205e-03 -2.49001924e-02  2.08260752e-02 -3.23820636e-02\n   2.99933311e-02 -2.60880608e-02 -7.66003579e-02  6.49915077e-03\n  -2.02356018e-02 -6.24884218e-02  2.37133019e-02 -2.00078059e-02\n  -7.18192235e-02  6.31196192e-04 -4.13793251e-02 -9.94707923e-03\n   3.92455533e-02  6.78057149e-02  6.30946532e-02  3.59565429e-02\n  -2.86177248e-02  7.02428892e-02 -2.51876414e-02 -2.44523049e-03\n  -6.07407726e-02 -9.53540672e-03  6.99850395e-02 -3.97541374e-02\n   2.18728036e-02  2.52876822e-02  8.79784755e-04  3.54576483e-02\n  -2.25261115e-02  9.44444984e-02  4.65292390e-03  2.76298542e-02\n  -2.53634546e-02 -1.07327970e-02  6.98907822e-02 -8.09371620e-02\n  -2.40128133e-02  4.02468955e-03  5.96243842e-03 -4.11641337e-02\n   8.32680520e-03 -8.34141765e-03 -6.35966361e-02  4.30045836e-02\n  -9.53956507e-03 -1.85988471e-02 -2.67096888e-02 -2.11820100e-03\n   2.23049019e-02  4.62925881e-02  8.28502607e-03  9.39000957e-03\n   4.69923578e-03 -2.42105555e-02 -6.11841604e-02  1.30644077e-02\n  -7.98915233e-03  1.44428462e-02 -2.32929061e-03  3.92193459e-02\n  -6.73010573e-02 -3.71826068e-02  2.99354047e-02  4.51661386e-02\n   1.44047746e-02  2.89236801e-03  9.34047997e-03  7.98757840e-03\n  -3.30587886e-02  6.74481094e-02  8.11144114e-02  8.31517950e-02\n  -4.12211120e-02  4.89871055e-02  5.48404967e-03 -2.28685476e-02\n   2.37471703e-02  1.01532964e-02  7.83643872e-02 -2.61383746e-02\n  -2.01958921e-02 -5.69503335e-03  7.81141296e-02  3.47997472e-02\n  -4.45018942e-03  1.66281387e-02  8.56331289e-02 -2.56437566e-02\n   2.88696140e-02 -9.11732297e-03 -5.60212880e-02  5.79179637e-02\n   5.24641313e-02 -2.19978802e-02  3.06734890e-02 -6.92165047e-02\n  -4.69815917e-02 -3.65407653e-02 -5.73706776e-02  3.54427099e-02\n  -2.73824744e-02  9.52671166e-04 -2.10476331e-02  1.98530573e-02\n  -4.15221378e-02 -2.03249305e-02  4.17145342e-02  4.83041182e-02\n   5.60690053e-02  2.08457629e-03  6.80542216e-02  2.80719586e-02\n   1.28379464e-02  1.91721134e-02 -1.31416675e-02 -6.23086765e-02\n  -4.32586186e-02  9.52165052e-02  3.48202474e-02  2.67874356e-02\n   4.11136448e-03  5.22289127e-02  5.26093990e-02  3.25968526e-02\n   6.73642233e-02 -7.71737397e-02  2.77026352e-02  5.32233529e-03\n   7.97110144e-03 -6.44645616e-02  6.72060326e-02 -4.76535819e-02\n   4.44538780e-02  8.52545798e-02 -1.34277754e-02 -2.90037300e-02\n  -3.62393521e-02 -7.67736211e-02  6.83569536e-02 -9.54318345e-02\n  -1.31209577e-02 -1.97148826e-02 -2.65974198e-02 -1.00267425e-01\n   1.51686333e-02  1.38387447e-02 -4.74292180e-03 -4.08426709e-02\n   4.90273908e-02  1.23700248e-02  2.95818178e-03 -7.56976306e-02\n   1.86104458e-02  4.14900370e-02  1.61427166e-02 -1.32738091e-02\n   3.51396501e-02  4.86939661e-02  3.37489112e-03 -1.48044545e-02\n  -5.13486601e-02 -3.67482528e-02  3.74265835e-02  6.56259386e-03\n  -3.13994251e-02 -3.71857174e-02  8.84642825e-02  6.60200864e-02\n   4.39814553e-02 -6.22263290e-02 -8.47223960e-03 -6.46299357e-03\n  -5.13792560e-02 -8.25269055e-03 -2.35791225e-02 -3.95909790e-03\n   6.17689304e-02  7.64907757e-03  8.00278559e-02 -3.93985119e-03\n  -3.96519415e-02  2.48139091e-02  6.92299679e-02  3.15599553e-02\n  -2.61446200e-02  4.52007726e-02 -1.18467622e-02  3.34791429e-02\n   2.08573975e-02  5.13666272e-02 -2.35446617e-02 -4.21010815e-02\n   8.54241848e-02 -1.01519637e-02  4.39880090e-03 -2.73628943e-02\n  -3.74757648e-02 -5.35963476e-03  4.25017923e-02  6.60659671e-02\n   3.07949893e-02  4.65630293e-02  5.63071296e-02  1.10708708e-02\n   2.27182675e-02  8.41138810e-02 -3.79729122e-02  1.58877838e-02\n  -7.18158577e-03 -9.87722725e-03  3.10769733e-02 -7.94399809e-03\n   1.86827332e-02  3.49501683e-03  3.37891988e-02 -4.87366430e-02\n  -4.63925786e-02  3.49931829e-02  1.53748784e-02 -5.30720921e-03\n   5.24307936e-02 -6.53624311e-02  2.50730738e-02  3.09303124e-02\n   7.82839358e-02 -2.23103072e-02 -1.53220082e-02 -9.93793681e-02\n  -9.31817964e-02 -6.46329392e-03 -2.70997616e-03 -6.79292977e-02\n  -7.63878003e-02 -5.42695969e-02 -2.04061568e-02 -2.85725128e-02\n   2.71191560e-02 -4.54211095e-03  8.08798224e-02 -2.17279363e-02\n  -1.77963497e-03 -6.24293201e-02  6.43987907e-03 -2.24191304e-02\n   2.86471541e-03 -6.62904140e-03 -5.69050983e-02  1.93417650e-02\n   3.72550972e-02 -8.05248879e-03 -1.48700587e-02  6.50391430e-02\n   3.53929773e-02 -4.57643867e-02  1.37632806e-02  8.65316018e-03\n   5.36587788e-03  3.69811766e-02 -1.89893339e-02 -1.76413003e-02\n  -5.38867489e-02 -4.07975800e-02 -5.98103851e-02 -2.39874050e-02\n  -8.02116394e-02  5.98880127e-02 -1.46319279e-02 -2.38077901e-02\n  -4.43020277e-02  4.40965360e-03 -9.29562747e-02 -3.42947058e-02\n   4.36521508e-02 -7.86472335e-02 -1.84473637e-02  3.11452542e-02\n   5.54760844e-02  3.11181843e-02 -3.87136005e-02  4.00627591e-03\n   9.12808161e-03  6.31642863e-02 -7.90860727e-02  2.66604703e-02\n  -1.05051196e-03  3.67832221e-02  1.77613031e-02  4.30113077e-02\n  -6.43125027e-02  8.70881751e-02  4.32735197e-02 -4.48854975e-02\n   4.90279980e-02  4.15431224e-02 -1.95042999e-03 -2.78928336e-02\n   2.53426041e-02 -5.98829128e-02  9.49921738e-03  7.31712803e-02\n   2.18690690e-02 -2.25726031e-02  4.37858365e-02  7.44571388e-02\n   6.27912283e-02 -2.37148348e-02  7.24392608e-02  1.53606143e-02\n   7.57678151e-02 -6.56951889e-02  1.18408795e-03  4.17453796e-02\n  -8.03039894e-02 -3.16790864e-02 -5.84682822e-03 -1.18964398e-02\n   3.31519768e-02  5.57449795e-02  1.11669032e-02  3.73796374e-02\n  -2.78657880e-02 -4.59355675e-03 -7.46896267e-02 -1.79246031e-02\n  -1.62295699e-02 -2.75057685e-02  4.01112251e-02  5.13412692e-02\n   3.00610755e-02 -1.21127004e-02  8.31539184e-02  5.98678328e-02\n  -3.19930688e-02  2.06097476e-02  9.62154716e-02 -8.20987895e-02\n  -6.35851622e-02 -8.48904252e-02 -1.73597448e-02 -2.92168725e-02\n   3.30147855e-02  2.54880209e-02  2.27643773e-02  5.95345907e-02\n  -4.57706079e-02  4.87065874e-02  5.90544380e-02 -6.84394455e-03\n   3.48349810e-02 -1.73334628e-02 -1.96440835e-02 -2.11943034e-02\n  -3.38818766e-02 -4.44716923e-02  5.01115210e-02 -6.59891590e-02\n  -5.94154261e-02  6.40743151e-02  5.26947193e-02  3.87082621e-02\n  -1.41436467e-02  1.04008196e-02  2.30377950e-02 -2.91589983e-02\n  -1.88109986e-02  6.87216595e-02  2.56887693e-02 -4.56612295e-04\n  -4.80121151e-02  1.67823266e-02  2.22593676e-02 -2.08404977e-02\n   3.56005132e-02 -5.57222404e-02 -8.09649453e-02  2.64421385e-02\n   1.78402327e-02  1.37637025e-02  1.54577671e-02 -1.61386766e-02\n   7.43572181e-03 -5.03949337e-02  1.04034021e-02 -2.04330739e-02]], shape=(1, 512), dtype=float32)\n"
+    }
+   ],
+   "source": [
+    "#calculating embeddings, in tensor format\n",
+    "embeddings = embed([utils.defs2str(definitions)[0]])\n",
+    "print(embeddings)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import tensorflow_hub as hub\n",
+    "from functools import partial\n",
+    "\n",
+    "def out(definition_vec, model, num2word, vocab_size):\n",
+    "    vocab_size = vocab_size + 1\n",
+    "    definition_string = \" \".join([num2word[num] for num in definition_vec])\n",
+    "    embedded_tens = model([definition_string])\n",
+    "    label = tf.one_hot(definition_vec, vocab_size)\n",
+    "    return embedded_tens, label[:, 1:]\n",
+    "return out"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "embed = hub.load(model_url)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "metadata": {},
+   "outputs": [
+    {
+     "output_type": "stream",
+     "name": "stdout",
+     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 512)]             0         \n_________________________________________________________________\nrepeat_vector (RepeatVector) (None, 54, 512)           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 54, 32)            69760     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 54, 64)            24832     \n_________________________________________________________________\ntime_distributed (TimeDistri (None, 54, 100)           6500      \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, 54, 46948)         4741748   \n=================================================================\nTotal params: 4,842,840\nTrainable params: 4,842,840\nNon-trainable params: 0\n_________________________________________________________________\n"
+    }
+   ],
+   "source": [
+    "#creating decoder model, taking in embedded strings, and calculating a resultant from them\n",
+    "\n",
+    "from tensorflow.keras.models import Model, Sequential\n",
+    "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM, RepeatVector, TimeDistributed, Lambda\n",
+    "from tensorflow.keras.optimizers import Adam\n",
+    "from tensorflow.keras.losses import categorical_crossentropy\n",
+    "\n",
+    "\n",
+    "inputlayer = Input(shape=(512,))\n",
+    "repeatlayer = RepeatVector(max_length)(inputlayer)\n",
+    "decodingLSTM1 = LSTM(32, return_sequences=True)(repeatlayer)\n",
+    "decodingLSTM2 = LSTM(64, return_sequences=True)(decodingLSTM1)\n",
+    "denseboi = TimeDistributed(Dense(100, activation=\"relu\"))(decodingLSTM2)\n",
+    "finalDense = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(denseboi)\n",
+    "output = finalDense\n",
+    "\n",
+    "model = Model(inputs=inputlayer, outputs=output)\n",
+    "optimizer = Adam(learning_rate = 0.0003)\n",
+    "model.compile(loss = categorical_crossentropy, optimizer = optimizer, metrics = [\"accuracy\"])\n",
+    "\n",
+    "model.summary()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "metadata": {},
+   "outputs": [
+    {
+     "output_type": "error",
+     "ename": "InternalError",
+     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
+      "\u001b[1;32m<ipython-input-11-b098dd1561d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://tfhub.dev/google/universal-sentence-encoder/4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefinitions2dataset_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#dataset = dataset.shuffle(1000).batch(config.batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32m<ipython-input-10-b755933031bf>\u001b[0m in \u001b[0;36mdefinitions2dataset_function\u001b[1;34m(model_url, num2word, vocab_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefinitions2dataset_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#creating embeddings from definitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0membed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefinition_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m     93\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m   \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m   \"\"\"\n\u001b[1;32m--> 528\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[0;32m    550\u001b[0m       loader = loader_cls(object_graph_proto,\n\u001b[0;32m    551\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                           export_dir)\n\u001b[0m\u001b[0;32m    553\u001b[0m       \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_info_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_functions_structures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_functions_captures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CPU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m       \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file_prefix_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m     \u001b[0mload_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[0mload_status\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         graph_view=self._graph_view)\n\u001b[0;32m   1282\u001b[0m     base.CheckpointPosition(\n\u001b[1;32m-> 1283\u001b[1;33m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[0;32m   1284\u001b[0m     load_status = CheckpointLoadStatus(\n\u001b[0;32m   1285\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    906\u001b[0m     restore_ops.extend(\n\u001b[0;32m    907\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[1;32m--> 908\u001b[1;33m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[1;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[0;32m    287\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[0;32m    288\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[1;32m--> 289\u001b[1;33m           validated_saveables).restore(self.save_path_tensor)\n\u001b[0m\u001b[0;32m    290\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    100\u001b[0m                                           structured_restored_tensors):\n\u001b[0;32m    101\u001b[0m       restore_ops[saveable.name] = saveable.restore(\n\u001b[1;32m--> 102\u001b[1;33m           restored_tensors, restored_shapes=None)\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m# Copy the restored tensor to the variable's device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_var_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m       \u001b[0mrestored_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[0;32m    116\u001b[0m           self.handle_op, self._var_shape, restored_tensor)\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3825\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3827\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
+      "\u001b[1;32mc:\\Users\\DS\\Desktop\\zhan8425_project\\projenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
+      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]"
+     ]
+    }
+   ],
+   "source": [
+    "#creating dataset\n",
+    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
+    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
+    "dataset = dataset.map(definitions2dataset_function(model_url, num2word, vocab_size))\n",
+    "#dataset = dataset.shuffle(1000).batch(config.batch_size)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": []
   }
  ]
 }
\ No newline at end of file
diff --git a/utils.py b/utils.py
index dc83b9e..e7557b5 100644
--- a/utils.py
+++ b/utils.py
@@ -1,5 +1,6 @@
 import os
 import numpy as np
+import tensorflow as tf
 
 #useful dicts and stuff
 pos_dict = {"a": "adj", "r": "adv", "n": "noun", "v": "verb"}
@@ -116,9 +117,18 @@ def defs_to_np(definitions, max_length, padding_num = 0):
     #return np.reshape(output, (output.shape + (1,))
     return output
 
+def defs2str(definitions):
+    '''converts a list of list of words to a list of strings'''
+    return [" ".join(each) for each in definitions]
 
+def to_one_hot(x):
+    vocab_size = 46948 + 1
+    #output = tf.zeros((x.shape)+(vocab_size,))
+    #mask = np.array(x) > 0
+    label = tf.one_hot(x, vocab_size)
+    return x, label[:, 1:]
 
-
+# creating embeddings
 
 
 
